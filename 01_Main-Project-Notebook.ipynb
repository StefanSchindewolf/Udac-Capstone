{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "--describe your project at a high level--\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Imports and Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import sys\n",
    "from nb_helpers import summarize_data, get_sas_definitions, read_sas_in_chunks\n",
    "\n",
    "# Logging\n",
    "logging.basicConfig(\n",
    "    level=logging.ERROR,\n",
    "    format='%(asctime)s %(levelname)s \\t %(message)s ',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "log = logging.getLogger('log')\n",
    "\n",
    "# Improve view\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Function definitions\n",
    "\n",
    "def quantify_data(df, type_choice=None, examples=10):\n",
    "    \"\"\" DOC STRING\"\"\"\n",
    "    # Set number of examples to be printed per value\n",
    "    # examples = 10\n",
    "    \n",
    "    # If type_choice is set, only the dtypes provided will be analysed\n",
    "    if type_choice is None:\n",
    "        # If not set, we simple analyze numeric and string data and\n",
    "        # print the result\n",
    "        type_choice = ['all']\n",
    "        print('Running Data Quantifier with parameter: ', ', '.join(type_choice),\\\n",
    "             ' and example threshhold is ', examples)\n",
    "    else:\n",
    "        print('Running Data Quantifier with parameter: ',  ', '.join(type_choice),\\\n",
    "             ' and example threshhold is ', examples)\n",
    "    \n",
    "    # Analysis section\n",
    "    if (('all' in type_choice) or ('numbers' in type_choice)):\n",
    "        # NUMERIC DATA ANALYSIS\n",
    "        sub_df = df.select_dtypes(exclude=['object'])\n",
    "        print('\\nQuantifying NUMERIC data types in columns:\\n',  ', '.join(sub_df.columns), '\\n')\n",
    "        # Get descriptive statistics\n",
    "        stat_df = sub_df.describe()\n",
    "        # Count missing values per column\n",
    "        miss_df = pd.DataFrame.from_dict({'Missing': sub_df.isna().sum()})\n",
    "        #miss_df = miss_df['Missing'].astype(int)\n",
    "        #mis_val_cols = miss_df.loc[miss_df['Missing'] > 0].columns\n",
    "        mis_val_cols = miss_df[miss_df > 0].dropna().index\n",
    "        # Count unique values per column\n",
    "        uniq_df = pd.DataFrame.from_dict({'Unique': sub_df.nunique()})\n",
    "        #uniq_df = uniq_df['Unique'].astype(int)\n",
    "        # Get list of example values for columns which have less than x unique values\n",
    "        uni_val_cols = uniq_df[uniq_df <= examples].dropna().index\n",
    "        uniq_df = uniq_df.transpose()\n",
    "        miss_df = miss_df.transpose()\n",
    "        stat_df = pd.concat([stat_df, uniq_df, miss_df])\n",
    "        display(stat_df)\n",
    "        print('Columns with missing values: ', ','.join(mis_val_cols), '\\n')\n",
    "        for unique_value_column in uni_val_cols:\n",
    "            unique_values = df[unique_value_column].drop_duplicates()\n",
    "            msg = 'Unique values in column \\'{}\\': \\n'.format(unique_value_column)\n",
    "            print(msg, unique_values.values, '\\n')\n",
    "        #print('Columns with missing values: ', ','.join(mis_val_cols))\n",
    "\n",
    "    if (('all' in type_choice) or ('object' in type_choice)):\n",
    "        # STRING DATA ANALYSIS\n",
    "        sub_df = df.select_dtypes(exclude=['float64'])\n",
    "        print('\\nQuantifying NON-NUMERIC data types in columns:\\n',  ', '.join(sub_df.columns))\n",
    "        stat_df = pd.DataFrame.from_dict(data=dict(sub_df.dtypes), orient='index', columns=['Datatype'])\n",
    "        stat_df['Lines'] = len(df)\n",
    "        stat_df['Non-Null'] = df.count()\n",
    "        stat_df['NaN'] = df.isna().sum()\n",
    "        stat_df['Fill-%'] = df.count() / len(df) *100\n",
    "        stat_df['Unique'] = df.nunique()\n",
    "        stat_df['Uniq-%'] = stat_df['Unique'] / stat_df['Lines'] *100\n",
    "        mis_val_cols = list(stat_df.loc[stat_df['Fill-%'] < 100].index)\n",
    "        uni_val_cols = list(stat_df.loc[stat_df['Unique'] <= examples].index)\n",
    "        display(stat_df.transpose())\n",
    "        print('Columns with missing values: ', ','.join(mis_val_cols), '\\n')\n",
    "        for unique_value_column in uni_val_cols:\n",
    "            unique_values = df[unique_value_column].drop_duplicates()\n",
    "            msg = 'Unique values in column \\'{}\\': \\n'.format(unique_value_column)\n",
    "            print(msg, unique_values.values, '\\n')\n",
    "    print(\"\\n\\nData Quantification Done\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Step 1 - Scoping and Data Gathering\n",
    "**Task: Scope the Project and Gather Data**\n",
    "\n",
    "*Identify and gather the data you'll be using for your project (at least two sources and more than 1 million rows). See Project Resources for ideas of what data you can use.*\n",
    "\n",
    "*Explain what end use cases you'd like to prepare the data for (e.g., analytics table, app back-end, source-of-truth database, etc.)*\n",
    "\n",
    "\n",
    "## Step 1a - General Scope and Data Gathering Description\n",
    "The Udacity provided datasets for the Capstone Project include:\n",
    "* I94 Immigration data from 2016 provided by U.S. Customs and Border Protection agency\n",
    "* World Temperature Data\n",
    "* U.S. cities demographic data\n",
    "* An airport code table\n",
    "\n",
    "Each dataset has been collected at least once for assessment. The findings are included in the following chapters of this notebook, even if the dataset is not used in Step 2.\n",
    "\n",
    "Regarding the scope itself the following findings are relevant:\n",
    "* **I94 Immigration data** is considered **in scope** regarding the following analytical tasks:\n",
    "    * Develop a scalable automated extraction procedure using Spark Data Lake\n",
    "    * Load and Transform the data into fact and dimension tables\n",
    "    * Develop Airflow routines to manage the process\n",
    "* **Airport Codes** are considered **in scope** and will be used\n",
    "    * to enrich the immigration dataset with complete and updated values\n",
    "* **World Temperature data** is considered **out of scope** since no analytics questions for this dataset in conjunction with immigration data could be identified _and_ the datasets' time periods do not overlap\n",
    "* **Demographic data** is considered\n",
    "\n",
    "**Approach to describe and gather data**\n",
    "\n",
    "Descriptions for each dataset will be given in the sections below. Each description shall include:\n",
    "1. A first read of the dataset using Python and Pandas default methods\n",
    "1. \"First Impression\" notes about the extracted data\n",
    "1. Analysis of dataset documentation, enclosed data dictionaries, etc.\n",
    "1. Findings about Data Meaning, Quality, possible relationsships and definitions for\n",
    "    1. Numeric columns (including missing values, uniqueness and descriptive statistics)\n",
    "    1. Non-numeric columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 1b - I94 Dataset of U.S. Customs and Border Protection department"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### A - I94 Immigration Dataset Description\n",
    "The dataset provided contains immigration data provided by US immigration authorities. Data is collected via form **I94** and contains data about people travelling from and to the US on people who are either **non United States citizens** or **lawful permanent residents** in the US.\n",
    "\n",
    "    “Form I-94, the Arrival-Departure Record Card, is a form used by the U.S. Customs and Border Protection (CBP) intended to keep track of the arrival and departure to/from the United States of people who are not United States citizens or lawful permanent residents (with the exception of those who are entering using the Visa Waiver Program or Compact of Free Association, using Border Crossing Cards, re-entering via automatic visa revalidation, or entering temporarily as crew members)” (https://en.wikipedia.org/wiki/Form_I-94)\n",
    "\n",
    "An overview of this dataset is also outlined [here] (https://travel.trade.gov/research/programs/i94/description.asp)\n",
    "\n",
    "Data files and formats:\n",
    "- Data files are stored in SAS (proprietary?) sas7bdat format\n",
    "- Per year a folder exists\n",
    "- Per month a file exists (~500 GB)\n",
    "\n",
    "Description file:\n",
    "- A description file for the fields was included, named *I94_SAS_Labels_Descriptions.SAS*\n",
    "- The file contains field descriptions for each column\n",
    "- And it contains value constraints for some columns, namely: *i94cnty, i94port, i94mode, i94addr*\n",
    "\n",
    "### B - I94 Immigration Data Data Gathering and first read\n",
    "\n",
    "As Pandas has a method to import SAS data we will be using this mechanism. The following code will read a defined number of lines only due to performance reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sas_chunk_reader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-74a31976c4f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfor_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m     \u001b[0;31m# Set the desired lines for each cycle here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0msas_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msas_chunk_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msas_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msas_file_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfor_lines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sas_chunk_reader' is not defined"
     ]
    }
   ],
   "source": [
    "# Read in the data using a wrapper for the read_sas() method\n",
    "# Configuration\n",
    "sas_file =  '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "sas_file_format = 'sas7bdat'\n",
    "max_lines=6000     # Set the desired line number here\n",
    "for_lines=2000     # Set the desired lines for each cycle here\n",
    "\n",
    "sas_df = sas_chunk_reader(sas_file, sas_file_format, max_lines, for_lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Summary on first read of data:**\n",
    "\n",
    "| **Column Name** | **Notes, comments and findings:**                  | **Recommended action items** |\n",
    "|------------|--------------------------------------------------|----------------------------|\n",
    "| all | (N) We are not importing everything here, since the files amount to about 6GB in total | |\n",
    "| |  (N) Using \"chunksize\" parameter and then breaking from the loop, so that we have handy 2.000 lines ||\n",
    "| all | In total 28 columns exist, 15 columns contain strings (object type) and 13 contain numbers (float64 type) | |\n",
    "| all | At first sight one can already spot unfamiliar date columns (arrdate, depdate, etc.) with various datatypes | |\n",
    "| all | Several rows have missing values | |\n",
    "| all | Some columns contain obviously integer values but float64 was assigned | |\n",
    "| all | Some categorical columns seem to exist | |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### C - Documentation and data description analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Documentation sources**\n",
    "\n",
    "A link was provided to the data source at the Visitor Arrivals Program: [LINK](https://travel.trade.gov/research/reports/i94/historical/2016.html)\n",
    "\n",
    "Following related pages were also analyzed:\n",
    "* Approved listing of [countries by world region](https://travel.trade.gov/research/programs/i94/1999-2020%20Region%20Dictionary.xlsx), stored as Excel file\n",
    "** Recommendation: use as source to validate data\n",
    "* A [Q&A section](https://travel.trade.gov/research/programs/ifs/qamythbuster.asp) which contains indications for completeness and accuracy of data\n",
    "** Those should be considered before making assumptions or draw conclusions from the data\n",
    "* Detailed descriptions about data collection [methodology](https://travel.trade.gov/research/programs/ifs/description.asp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Parsing the description file / data dictionary**\n",
    "\n",
    "The workspace contains a field description file for the dataset named `I94_SAS_Labels_Descriptions.SAS`\n",
    "\n",
    "The file seems pretty well structured, so I wrote a quick parser to automatically check the description file (see [SAS-Description-Parser](https://r766466c839826xjupyterlnnfq3jud.udacity-student-workspaces.com/lab/tree/SAS-Description-Parser.ipynb) for further details).\n",
    "\n",
    "**Definitions**\n",
    "\n",
    "| **Variable name** | **Data Type** | **Description** |\n",
    "|---------------|---------------|---------------|\n",
    "| i94yr | float64 | 4 digit year |\n",
    "| i94mon | float64 | Numeric month |\n",
    "| i94cit | float64 | This format shows all the valid and invalid codes for processing |\n",
    "| i94res | float64 | This format shows all the valid and invalid codes for processing |\n",
    "| i94port | object | This format shows all the valid and invalid codes for processing |\n",
    "| arrdate | float64 | is the Arrival Date in the USA. It is a SAS date numeric field that apermament format has not been applied.  Please apply whichever date formatpermament format has not been applied.  Please apply whichever date format |\n",
    "| i94mode | float64 | There are missing values as well as not reported (9) |\n",
    "| i94addr | object | There is lots of invalid codes in this variable and the list belowThere is lots of invalid codes in this variable and the list below |\n",
    "| depdate | float64 | is the Departure Date from the USA. It is a SAS date numeric field thata permament format has not been applied.  Please apply whichever date formata permament format has not been applied.  Please apply whichever date format |\n",
    "| i94bir | float64 | Age of Respondent in Years |\n",
    "| i94visa | float64 | Visa codes collapsed into three categories:1 = Business2 = Pleasure3 = Student*/ |\n",
    "| count | float64 | Used for summary statistics |\n",
    "| dtadfile | object | Character Date Field |\n",
    "| visapost | object | Department of State where where Visa was issued |\n",
    "| occup | object | Occupation that will be performed in U.S. |\n",
    "| entdepa | object | Arrival Flag |\n",
    "| entdepd | object | Departure Flag |\n",
    "| entdepu | object | Update Flag |\n",
    "| matflag | object | Match flag |\n",
    "| biryear | float64 | 4 digit year of birth |\n",
    "| dtaddto | object | Character Date Field |\n",
    "| gender | object | Non |\n",
    "| insnum | object | INS number |\n",
    "| airline | object | Airline used to arrive in U.S. |\n",
    "| admnum | float64 | Admission Number |\n",
    "| fltno | object | Flight number of Airline used to arrive in U.S. |\n",
    "| visatype | object | Class of admission legally admitting the non |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Summary on data documentation and descriptions:**\n",
    "\n",
    "| **Column Name** | **Notes, comments and findings:**                  | **Recommended action items** |\n",
    "|------------|--------------------------------------------------|----------------------------|\n",
    "| `i94cnty, i94port, i94mode, i94addr` | have value constraints (lists with allowed entry values) | Change data types, validate content (see below) | |\n",
    "| `i94cnty` | contains country short codes and their corresponding state names | Change to category field |\n",
    "| `i94port` | contains port/airport codes from various cities, without specific selection criteria as it seems (most of the codes are cities in the US but we also see city codes from Europe and Asia) | Change data type to string, Validate airport table using airport-codes_csv.csv| \n",
    "| `i94mode` | is a code for the way of travelling (by Air, by Sea or by Land) or unknown | Change to category field |\n",
    "| `i94addr` | is a code for the state in which this immigrants temporary address is located (aka \"First Intended Address\") | Change to category field |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### D - Analysis of numeric columns\n",
    "The Pandas describe() function creates a basic set of descriptive statistics for each numeric column in the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "summarize_data(sas_df, ['numbers'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Summary on numeric data:**\n",
    "\n",
    "| **Column Name** | **Notes, comments and findings:**                  | **Recommended action items** |\n",
    "|------------|--------------------------------------------------|----------------------------|\n",
    "| `cicid` |is unique for all 2.000 lines (check `len(sas_df['cicid'].unique())`) and appears to be the primary key for each record | Change to int, Use as primary key|\n",
    "| | The following columns appear to indicate datetime related values: |\n",
    "| `i94yr` |indicating the year the I94 form was filled and 'i94mon' indicating the month | Change to int |\n",
    "| `arrdate` |is the immigrants arrival date | Change to datetime64 |\n",
    "| `depdate` |the date of the immigrants (planned) departure | Change to datetime64 |\n",
    "| `i94mode` | has already been identified as a category variable, the integers here are just codes indicating if the immigrant travelled by Land, Air or Sea (or unknown) | Change to category|\n",
    "| `i94visa` | was not identified correctly by my parser it seems, it has value constraints (* 1 = Business, 2 = Pleasure,3 = Student)  | Change to category|\n",
    "| `i94cit` and `i94res` | are again not numeric but indicate the immigrant's countries of citizenship (\"cit\") and residence (res) | Change to category, Validate date using value constraints |\n",
    "|`admnum` | is the admission number | Use as key variable to connect several rows |\n",
    "|`i94bir` |appears to be the immigrant's age at the time of admission (in other words it's the time delta between `i94yr`and `biryear` | Change to int|\n",
    "| `biryear` | marks the immigrants birthyear | Change to int |\n",
    "| `count` |is for statistical purposes according to the description | Change to int |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### E - Analysis of non-numeric columns\n",
    "Measuring the number of NaN entries and unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "quantify_data(sas_df, ['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Summary on non-numeric data:**\n",
    "\n",
    "| **Column Name** | **Notes, comments and findings:**                  | **Recommended action items** |\n",
    "|------------|--------------------------------------------------|----------------------------|\n",
    "| `i94prt, i94addr, dtadfile` | Value constraints exist | Change to category, Validate against list of constraints |\n",
    "| `dtadfile` |is the date on which the form was entered into the database | Change to datetime64 |\n",
    "| `dtaddto` |is the date the immigrant is admissioned to stay in the US | Change to datetime64 |\n",
    "| `visapost, occup` | rarely filled, not fit for analysis | \n",
    "| `entdepa, entdepd,entdepu,matflag,` | Unclear description in the data dictionary | Exclude from analyis |\n",
    "| `gender` | Immigrant gender | Change to category |\n",
    "| `insnum` | Immigration registration number, not filled in data sample | Check if field is filled in complete dataset | |\n",
    "| `visatype` | Type of issued visa | Check [online sources](https://travel.trade.gov/research/programs/i94/methodology.asp) for list of possible types |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### F - Dataset conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Summary on non-numeric data:**\n",
    "\n",
    "| **Column Name** | **Commends and findings:**                  | **Recommended action items** |\n",
    "|------------|--------------------------------------------------|----------------------------|\n",
    "| <FELD> | <COMMENT, NOTE, FINDING> | <ACTION>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 1c - World Temperature Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### A - World Temperature Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The World Temperature Dataset contains temperatures on land by city on a global scale. A detailed discription can be found [here](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data).\n",
    "\n",
    "The source indicates that other datasets exist which summarize the data e.g. by country or major cities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### B - Documentation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The dataset from kaggle provides a documentation on its hosting [site](https://www.kaggle.com/colinpbowen/starter-climate-change-earth-surface-e24bc90c-4)\n",
    "\n",
    "The set consists of seven columns:\n",
    "* `dt` is the temperatures measurement timestamp\n",
    "* `AverageTemperature` displays the average temperature in celsius degrees\n",
    "* `AgerageTemperatureUncertainty` shows possible deviations from average (95% confidence)\n",
    "* `City` - name of the city, has 3.448 distinct values\n",
    "* `Latitude, Longitude` - location of measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### C - World Temperature Data Gathering and first read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "As Pandas has a method to import CSV data we will be using this mechanism.\n",
    "\n",
    "Instead of reading just a chunk of the file we will read it in full here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "fname = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "csv_df = pd.read_csv(fname)\n",
    "size = int(getsize(fname) / 1024 / 1024)\n",
    "print('Reading {} (Size: {} Mb) lines from file {}\\n'.format(len(csv_df), fname, size))\n",
    "print('First lines of data and data types:')\n",
    "csv_df_typ = pd.DataFrame(csv_df.dtypes).transpose()\n",
    "display(csv_df.head(), csv_df_typ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Summary on first read:**\n",
    "\n",
    "| **Column Name** | **Commends and findings:**                  | **Recommended action items** |\n",
    "|------------|--------------------------------------------------|----------------------------|\n",
    "| all | Dataset contains in total over 8.5m rows | |\n",
    "| `dt` | starting in 1743 | Convert to datetime64 |\n",
    "| `AverageTemperature` | mind the missing values | Check for isna() |\n",
    "| `AverageTemperatureUncertainty` | same as above | |\n",
    "| `City, Country` | None | |\n",
    "| `Latitude, Longitude` | |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### D - Analysis of numeric columns in Temperature Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Only two numeric columns were identified:  `AverageTemperature`, `AverageTemperatureUncertainty`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "summarize_data(csv_df, ['numbers'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Summary on numeric data:**\n",
    "\n",
    "| **Column Name** | **Notes, comments and findings:**                  | **Recommended action items** |\n",
    "|------------|--------------------------------------------------|----------------------------|\n",
    "| `AverageTemperature` | About 364.000 missing values | Exclude NaN from analysis |\n",
    "| | \n",
    "| `AverageTemperatureUncertainty` | About 364.000 missing values, which is expected due to missing temperature data | Exclude NaN from analysis |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### E - Analysis of non-numeric columns in Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Non-numeric data columns, qualitative analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "summarize_data(csv_df, ['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Convert \"dt\" to datetime and sort, then check latest measurement date\n",
    "\n",
    "csv_df[['dt']] = csv_df[['dt']].astype('datetime64')\n",
    "csv_df = csv_df.sort_values(by=['dt'], ascending=False)\n",
    "print('The last datapoint is from the following date: {:.10}'.format(csv_df['dt'].head(1).values[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Check distribution of data points per City\n",
    "\n",
    "# Count datapoints per city\n",
    "count_df = csv_df[['City', 'dt']].copy()\n",
    "count_df = count_df.groupby(by=['City']).count()\n",
    "count_df = count_df.sort_values(by='dt', ascending=False)\n",
    "entries = len(csv_df)\n",
    "num_of_cit = len(count_df)\n",
    "print('Average datapoints per city: {:6.0f} entries'.format((entries / num_of_cit)))\n",
    "print('City with most data points: {}\\t\\t\\t{} entries'.format(count_df.head(1).index[0], count_df['dt'].head(1).values[0]))\n",
    "print('City with least data points: {}\\t\\t\\t{} entries'.format(count_df.tail(1).index[0], count_df['dt'].tail(1).values[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Summary:**\n",
    "\n",
    "| **Column Name** | **Notes, comments and findings:**                  | **Recommended action items** |\n",
    "|------------|--------------------------------------------------|----------------------------|\n",
    "| `dt` | The \"freshest\" data point is from September 2013 | Match with immigration data |\n",
    "| all | There is a significant **imbalance in the number of data points**: While the average is 2.494 entries, the city with most entries has 9.545 and the city with least entries has 1.581 entries | |\n",
    "| all | Also the datapoints per day are varying between about 700 and 3500 per day | |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### F - Dataset conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The \"World Temperature Dataset is not well suited to be analyzed in conjunction with the Immigration Data, since there is no time period overlap. Without temperature data from the time period of the provided immigration data no signifant findings from data analyses can be expected.\n",
    "\n",
    "The World Temperature Dataset is ruled **out of scope**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Summary:**\n",
    "\n",
    "| **Column Name** | **Notes, comments and findings:**                  | **Recommended action items** |\n",
    "|------------|--------------------------------------------------|----------------------------|\n",
    "| <FELD> | <COMMENT, NOTE, FINDING> | <ACTION>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 1d U.S. City Demographic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### A - Demographic Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "A dataset of demographic data is provided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### B - Demographic Data Gathering and first read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "As Pandas has a method to import CSV data we will be using this mechanism. The following code will read a defined number of lines only due to performance reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dem_df = pd.read_csv(\"us-cities-demographics.csv\", sep=\";\")\n",
    "dem_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### C - Documentation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Lorem Ipsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Summary:**\n",
    "\n",
    "| **Column Name** | **Notes, comments and findings:**                  | **Recommended action items** |\n",
    "|------------|--------------------------------------------------|----------------------------|\n",
    "| <FELD> | <COMMENT, NOTE, FINDING> | <ACTION>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Summary on non-numeric data:**\n",
    "\n",
    "| **Column Name** | **Commends and findings:**                  | **Recommended action items** |\n",
    "|------------|--------------------------------------------------|----------------------------|\n",
    "| <FELD> | <COMMENT, NOTE, FINDING> | <ACTION>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### D - Analysis of numeric columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Lorem Ipsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "summarize_data(dem_df, ['numbers'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Summary:**\n",
    "\n",
    "| **Column Name** | **Notes, comments and findings:**                  | **Recommended action items** |\n",
    "|------------|--------------------------------------------------|----------------------------|\n",
    "| <FELD> | <COMMENT, NOTE, FINDING> | <ACTION>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### E - Analysis of non-numeric columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Lorem Ipsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "summarize_data(dem_df, ['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Summary:**\n",
    "\n",
    "| **Column Name** | **Notes, comments and findings:**                  | **Recommended action items** |\n",
    "|------------|--------------------------------------------------|----------------------------|\n",
    "| <FELD> | <COMMENT, NOTE, FINDING> | <ACTION>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Summary on non-numeric data:**\n",
    "\n",
    "| **Column Name** | **Commends and findings:**                  | **Recommended action items** |\n",
    "|------------|--------------------------------------------------|----------------------------|\n",
    "| <FELD> | <COMMENT, NOTE, FINDING> | <ACTION>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### F - Dataset conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Lorem Ipsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Summary:**\n",
    "\n",
    "| **Column Name** | **Notes, comments and findings:**                  | **Recommended action items** |\n",
    "|------------|--------------------------------------------------|----------------------------|\n",
    "| <FELD> | <COMMENT, NOTE, FINDING> | <ACTION>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Summary on non-numeric data:**\n",
    "\n",
    "| **Column Name** | **Commends and findings:**                  | **Recommended action items** |\n",
    "|------------|--------------------------------------------------|----------------------------|\n",
    "| <FELD> | <COMMENT, NOTE, FINDING> | <ACTION>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 1e - Airport Code Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### A - World Temperature Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Lorem Ipsum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### B - World Temperature Data Gathering and first read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "As Pandas has a method to import CSV data we will be using this mechanism. The following code will read a defined number of lines only due to performance reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "fname = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "csv_df = pd.read_csv(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### C - Documentation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Lorem Ipsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Summary:**\n",
    "\n",
    "| **Column Name** | **Notes, comments and findings:**                  | **Recommended action items** |\n",
    "|------------|--------------------------------------------------|----------------------------|\n",
    "| <FELD> | <COMMENT, NOTE, FINDING> | <ACTION>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Summary on non-numeric data:**\n",
    "\n",
    "| **Column Name** | **Commends and findings:**                  | **Recommended action items** |\n",
    "|------------|--------------------------------------------------|----------------------------|\n",
    "| <FELD> | <COMMENT, NOTE, FINDING> | <ACTION>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### D - Analysis of numeric columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Lorem Ipsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "summarize_data(df, 'numbers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Summary:**\n",
    "\n",
    "| **Column Name** | **Notes, comments and findings:**                  | **Recommended action items** |\n",
    "|------------|--------------------------------------------------|----------------------------|\n",
    "| <FELD> | <COMMENT, NOTE, FINDING> | <ACTION>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Summary on non-numeric data:**\n",
    "\n",
    "| **Column Name** | **Commends and findings:**                  | **Recommended action items** |\n",
    "|------------|--------------------------------------------------|----------------------------|\n",
    "| <FELD> | <COMMENT, NOTE, FINDING> | <ACTION>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### E - Analysis of non-numeric columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Lorem Ipsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Summary:**\n",
    "\n",
    "| **Column Name** | **Notes, comments and findings:**                  | **Recommended action items** |\n",
    "|------------|--------------------------------------------------|----------------------------|\n",
    "| <FELD> | <COMMENT, NOTE, FINDING> | <ACTION>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Summary on non-numeric data:**\n",
    "\n",
    "| **Column Name** | **Commends and findings:**                  | **Recommended action items** |\n",
    "|------------|--------------------------------------------------|----------------------------|\n",
    "| <FELD> | <COMMENT, NOTE, FINDING> | <ACTION>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### F - Dataset conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Lorem Ipsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Summary:**\n",
    "\n",
    "| **Column Name** | **Notes, comments and findings:**                  | **Recommended action items** |\n",
    "|------------|--------------------------------------------------|----------------------------|\n",
    "| <FELD> | <COMMENT, NOTE, FINDING> | <ACTION>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Summary on non-numeric data:**\n",
    "\n",
    "| **Column Name** | **Commends and findings:**                  | **Recommended action items** |\n",
    "|------------|--------------------------------------------------|----------------------------|\n",
    "| <FELD> | <COMMENT, NOTE, FINDING> | <ACTION>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "\t\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport().getOrCreate()\n",
    "df_spark =spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#write to parquet\n",
    "df_spark.write.parquet(\"sas_data\")\n",
    "df_spark=spark.read.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Performing cleaning tasks here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Perform quality checks here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
