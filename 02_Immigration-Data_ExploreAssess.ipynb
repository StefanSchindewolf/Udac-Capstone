{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Immigration Data ETL\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "--describe your project at a high level--\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 2 Explore and assess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Methodical Approach\n",
    "Lorem Ipsum\n",
    "\n",
    "Transformation actions will be noted in brackets e.g. (TFA-1) for the first action and so on. This is to keep an overview of what needs to be implemented in the etl.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Imports and Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from os.path import getsize\n",
    "from nb_helpers import summarize_data, get_sas_definitions, read_sas_in_chunks, read_csv_print\n",
    "\n",
    "# Logging\n",
    "logging.basicConfig(\n",
    "    level=logging.ERROR,\n",
    "    format='%(asctime)s %(levelname)s \\t %(message)s ',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "log = logging.getLogger('log')\n",
    "\n",
    "# Improve view\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Reading data files into Spark Dataframes\n",
    "The next cell contains the file locations for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# File locations\n",
    "dem_file = \"us-cities-demographics.csv\"\n",
    "sas_file = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "air_file = 'airport-codes_csv.csv'\n",
    "# If working on a sample of the large immigration dataset, set your sample size here:\n",
    "sample_size = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Then we setup the Spark Session and read all 3 files into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "\t\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport().getOrCreate()\n",
    "\n",
    "imm_df = spark.read.format('com.github.saurfang.sas.spark').load(sas_file)\n",
    "air_df = spark.read.csv(air_file, header=True)\n",
    "dem_df = spark.read.csv(dem_file, header=True)\n",
    "df_list = {'imm_df': imm_df, 'air_df': air_df, 'dem_df': dem_df}\n",
    "imm_full = imm_df\n",
    "imm_df = imm_full.sample(sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Explore and Assess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Display schemas created automatically by Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- ident: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- elevation_ft: string (nullable = true)\n",
      " |-- continent: string (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      " |-- iso_region: string (nullable = true)\n",
      " |-- municipality: string (nullable = true)\n",
      " |-- gps_code: string (nullable = true)\n",
      " |-- iata_code: string (nullable = true)\n",
      " |-- local_code: string (nullable = true)\n",
      " |-- coordinates: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- City;State;Median Age;Male Population;Female Population;Total Population;Number of Veterans;Foreign-born;Average Household Size;State Code;Race;Count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imm_df.printSchema()\n",
    "air_df.printSchema()\n",
    "dem_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Note** (TFA-1) Demographics data file was imported as a one-column file due to ';' being used as delimiter. We read the file again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Median Age: string (nullable = true)\n",
      " |-- Male Population: string (nullable = true)\n",
      " |-- Female Population: string (nullable = true)\n",
      " |-- Total Population: string (nullable = true)\n",
      " |-- Number of Veterans: string (nullable = true)\n",
      " |-- Foreign-born: string (nullable = true)\n",
      " |-- Average Household Size: string (nullable = true)\n",
      " |-- State Code: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      " |-- Count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dem_df = spark.read.csv(dem_file, header=True, sep=';')\n",
    "dem_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Note**: (TFA-2) For easier handling we strip columns of spaces, apply lower case and replace inner spaces and '-' with underscore '_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['city',\n",
       " 'state',\n",
       " 'median_age',\n",
       " 'male_population',\n",
       " 'female_population',\n",
       " 'total_population',\n",
       " 'number_of_veterans',\n",
       " 'foreign_born',\n",
       " 'average_household_size',\n",
       " 'state_code',\n",
       " 'race',\n",
       " 'count']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def trim_col_headers(df):\n",
    "    for col in df.columns:\n",
    "        changed_col = col.strip().lower().replace(' ', '_').replace('-', '_')\n",
    "        df = df.withColumnRenamed(col, changed_col)\n",
    "    return df\n",
    "\n",
    "result_df = trim_col_headers(dem_df)\n",
    "result_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql.window import Window\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, LongType, TimestampType, DateType\n",
    "from pyspark.sql.functions import pandas_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154386"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imm_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'printSchema'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-2f4548b9c385>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprintSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'printSchema'"
     ]
    }
   ],
   "source": [
    "re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Date Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "\"cannot resolve '`column`' given input columns: [arrdate, depdate, fltno, i94addr, matflag, entdepu, biryear, gender, i94bir, admnum, i94res, airline, i94cit, i94visa, cicid, dtadfile, entdepa, insnum, visatype, occup, i94mode, i94yr, dtaddto, epoch_start, visapost, count, entdepd, i94mon, i94port]; line 1 pos 22;\\n'Project [cicid#0, i94yr#1, i94mon#2, i94cit#3, i94res#4, i94port#5, 'date_add(epoch_start#2792, 'column) AS arrdate#2852, i94mode#7, i94addr#8, depdate#9, i94bir#10, i94visa#11, count#12, dtadfile#13, visapost#14, occup#15, entdepa#16, entdepd#17, entdepu#18, matflag#19, biryear#20, dtaddto#21, gender#22, insnum#23, ... 5 more fields]\\n+- Project [cicid#0, i94yr#1, i94mon#2, i94cit#3, i94res#4, i94port#5, cast(arrdate#6 as int) AS arrdate#2822, i94mode#7, i94addr#8, depdate#9, i94bir#10, i94visa#11, count#12, dtadfile#13, visapost#14, occup#15, entdepa#16, entdepd#17, entdepu#18, matflag#19, biryear#20, dtaddto#21, gender#22, insnum#23, ... 5 more fields]\\n   +- Project [cicid#0, i94yr#1, i94mon#2, i94cit#3, i94res#4, i94port#5, arrdate#6, i94mode#7, i94addr#8, depdate#9, i94bir#10, i94visa#11, count#12, dtadfile#13, visapost#14, occup#15, entdepa#16, entdepd#17, entdepu#18, matflag#19, biryear#20, dtaddto#21, gender#22, insnum#23, ... 5 more fields]\\n      +- Project [cicid#0, i94yr#1, i94mon#2, i94cit#3, i94res#4, i94port#5, arrdate#6, i94mode#7, i94addr#8, depdate#9, i94bir#10, i94visa#11, count#12, dtadfile#13, visapost#14, occup#15, entdepa#16, entdepd#17, entdepu#18, matflag#19, biryear#20, dtaddto#21, gender#22, insnum#23, ... 5 more fields]\\n         +- Sample 0.0, 0.05, false, 7332791063795104365\\n            +- Relation[cicid#0,i94yr#1,i94mon#2,i94cit#3,i94res#4,i94port#5,arrdate#6,i94mode#7,i94addr#8,depdate#9,i94bir#10,i94visa#11,count#12,dtadfile#13,visapost#14,occup#15,entdepa#16,entdepd#17,entdepu#18,matflag#19,biryear#20,dtaddto#21,gender#22,insnum#23,... 4 more fields] SasRelation(../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat,null,Configuration: core-default.xml, core-site.xml, mapred-default.xml, mapred-site.xml, yarn-default.xml, yarn-site.xml, hdfs-default.xml, hdfs-site.xml,0)\\n\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o614.withColumn.\n: org.apache.spark.sql.AnalysisException: cannot resolve '`column`' given input columns: [arrdate, depdate, fltno, i94addr, matflag, entdepu, biryear, gender, i94bir, admnum, i94res, airline, i94cit, i94visa, cicid, dtadfile, entdepa, insnum, visatype, occup, i94mode, i94yr, dtaddto, epoch_start, visapost, count, entdepd, i94mon, i94port]; line 1 pos 22;\n'Project [cicid#0, i94yr#1, i94mon#2, i94cit#3, i94res#4, i94port#5, 'date_add(epoch_start#2792, 'column) AS arrdate#2852, i94mode#7, i94addr#8, depdate#9, i94bir#10, i94visa#11, count#12, dtadfile#13, visapost#14, occup#15, entdepa#16, entdepd#17, entdepu#18, matflag#19, biryear#20, dtaddto#21, gender#22, insnum#23, ... 5 more fields]\n+- Project [cicid#0, i94yr#1, i94mon#2, i94cit#3, i94res#4, i94port#5, cast(arrdate#6 as int) AS arrdate#2822, i94mode#7, i94addr#8, depdate#9, i94bir#10, i94visa#11, count#12, dtadfile#13, visapost#14, occup#15, entdepa#16, entdepd#17, entdepu#18, matflag#19, biryear#20, dtaddto#21, gender#22, insnum#23, ... 5 more fields]\n   +- Project [cicid#0, i94yr#1, i94mon#2, i94cit#3, i94res#4, i94port#5, arrdate#6, i94mode#7, i94addr#8, depdate#9, i94bir#10, i94visa#11, count#12, dtadfile#13, visapost#14, occup#15, entdepa#16, entdepd#17, entdepu#18, matflag#19, biryear#20, dtaddto#21, gender#22, insnum#23, ... 5 more fields]\n      +- Project [cicid#0, i94yr#1, i94mon#2, i94cit#3, i94res#4, i94port#5, arrdate#6, i94mode#7, i94addr#8, depdate#9, i94bir#10, i94visa#11, count#12, dtadfile#13, visapost#14, occup#15, entdepa#16, entdepd#17, entdepu#18, matflag#19, biryear#20, dtaddto#21, gender#22, insnum#23, ... 5 more fields]\n         +- Sample 0.0, 0.05, false, 7332791063795104365\n            +- Relation[cicid#0,i94yr#1,i94mon#2,i94cit#3,i94res#4,i94port#5,arrdate#6,i94mode#7,i94addr#8,depdate#9,i94bir#10,i94visa#11,count#12,dtadfile#13,visapost#14,occup#15,entdepa#16,entdepd#17,entdepu#18,matflag#19,biryear#20,dtaddto#21,gender#22,insnum#23,... 4 more fields] SasRelation(../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat,null,Configuration: core-default.xml, core-site.xml, mapred-default.xml, mapred-site.xml, yarn-default.xml, yarn-site.xml, hdfs-default.xml, hdfs-site.xml,0)\n\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$3.applyOrElse(CheckAnalysis.scala:110)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$3.applyOrElse(CheckAnalysis.scala:107)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:278)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:278)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:275)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:275)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.org$apache$spark$sql$catalyst$trees$TreeNode$$mapChild$2(TreeNode.scala:295)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4$$anonfun$apply$13.apply(TreeNode.scala:354)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:104)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:354)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:324)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:275)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:275)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:275)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:324)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:275)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:93)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:93)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:105)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:105)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:104)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:116)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1$2.apply(QueryPlan.scala:121)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.immutable.List.map(List.scala:296)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:121)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$2.apply(QueryPlan.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:126)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:93)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:107)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:85)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:127)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$class.checkAnalysis(CheckAnalysis.scala:85)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:95)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:108)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:105)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:105)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:57)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:55)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:47)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:78)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withPlan(Dataset.scala:3406)\n\tat org.apache.spark.sql.Dataset.select(Dataset.scala:1334)\n\tat org.apache.spark.sql.Dataset.withColumns(Dataset.scala:2252)\n\tat org.apache.spark.sql.Dataset.withColumn(Dataset.scala:2219)\n\tat sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-7c573754a01e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mresult_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msasdate_to_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimm_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'arrdate'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'depdate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mresult_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'arrdate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-7c573754a01e>\u001b[0m in \u001b[0;36msasdate_to_date\u001b[0;34m(df, column_list)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumn_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\"date_add(epoch_start, column)\"\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mwithColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   1987\u001b[0m         \"\"\"\n\u001b[1;32m   1988\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"col should be Column\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1989\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1991\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mignore_unicode_prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: \"cannot resolve '`column`' given input columns: [arrdate, depdate, fltno, i94addr, matflag, entdepu, biryear, gender, i94bir, admnum, i94res, airline, i94cit, i94visa, cicid, dtadfile, entdepa, insnum, visatype, occup, i94mode, i94yr, dtaddto, epoch_start, visapost, count, entdepd, i94mon, i94port]; line 1 pos 22;\\n'Project [cicid#0, i94yr#1, i94mon#2, i94cit#3, i94res#4, i94port#5, 'date_add(epoch_start#2792, 'column) AS arrdate#2852, i94mode#7, i94addr#8, depdate#9, i94bir#10, i94visa#11, count#12, dtadfile#13, visapost#14, occup#15, entdepa#16, entdepd#17, entdepu#18, matflag#19, biryear#20, dtaddto#21, gender#22, insnum#23, ... 5 more fields]\\n+- Project [cicid#0, i94yr#1, i94mon#2, i94cit#3, i94res#4, i94port#5, cast(arrdate#6 as int) AS arrdate#2822, i94mode#7, i94addr#8, depdate#9, i94bir#10, i94visa#11, count#12, dtadfile#13, visapost#14, occup#15, entdepa#16, entdepd#17, entdepu#18, matflag#19, biryear#20, dtaddto#21, gender#22, insnum#23, ... 5 more fields]\\n   +- Project [cicid#0, i94yr#1, i94mon#2, i94cit#3, i94res#4, i94port#5, arrdate#6, i94mode#7, i94addr#8, depdate#9, i94bir#10, i94visa#11, count#12, dtadfile#13, visapost#14, occup#15, entdepa#16, entdepd#17, entdepu#18, matflag#19, biryear#20, dtaddto#21, gender#22, insnum#23, ... 5 more fields]\\n      +- Project [cicid#0, i94yr#1, i94mon#2, i94cit#3, i94res#4, i94port#5, arrdate#6, i94mode#7, i94addr#8, depdate#9, i94bir#10, i94visa#11, count#12, dtadfile#13, visapost#14, occup#15, entdepa#16, entdepd#17, entdepu#18, matflag#19, biryear#20, dtaddto#21, gender#22, insnum#23, ... 5 more fields]\\n         +- Sample 0.0, 0.05, false, 7332791063795104365\\n            +- Relation[cicid#0,i94yr#1,i94mon#2,i94cit#3,i94res#4,i94port#5,arrdate#6,i94mode#7,i94addr#8,depdate#9,i94bir#10,i94visa#11,count#12,dtadfile#13,visapost#14,occup#15,entdepa#16,entdepd#17,entdepu#18,matflag#19,biryear#20,dtaddto#21,gender#22,insnum#23,... 4 more fields] SasRelation(../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat,null,Configuration: core-default.xml, core-site.xml, mapred-default.xml, mapred-site.xml, yarn-default.xml, yarn-site.xml, hdfs-default.xml, hdfs-site.xml,0)\\n\""
     ]
    }
   ],
   "source": [
    "def sasdate_to_date(df=None, column_list=[]):\n",
    "    #epoch_start = spark.createDataFrame([('1960-01-01',)], ['dt'])\n",
    "    df = df.withColumn('epoch_start', F.lit(\"01-01-1960 00:00:00\"))\n",
    "    df = df.withColumn('epoch_start', F.to_date(F.col('epoch_start'), \"dd-M-yyyy\"))\n",
    "    for column in column_list:\n",
    "        df = df.withColumn(column, df.arrdate.cast('int'))\n",
    "        df = df.withColumn(column, F.expr(\"\"\"date_add(epoch_start, df.column)\"\"\"))\n",
    "    return df\n",
    "\n",
    "result_df = sasdate_to_date(imm_df, ['arrdate', 'depdate'])\n",
    "result_df.select('arrdate').show()\n",
    "\n",
    "                 #F.col('epoch_start'), F.date_add('epoch_start', F.col('arrdate'))).show()\n",
    "\n",
    "\n",
    "\n",
    "#work_df = work_df.withColumn('epoch_start_new', to_date(work_df.epoch_start, 'yyyy-MM-dd'))\n",
    "#work_df = work_df.withColumn('new_arr', date_add('epoch-start', 'arrdate'))\n",
    "#print(type(result_df), result_df.head(), result_df.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: integer (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      " |-- epoch_start: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "work_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------+\n",
      "|count(CASE WHEN (isnan(entdepd) OR (entdepd IS NULL)) THEN true END)|\n",
      "+--------------------------------------------------------------------+\n",
      "|                                                              138429|\n",
      "+--------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_list = {'imm_df': imm_df, 'air_df': air_df, 'dem_df': dem_df}\n",
    "for name, df in df_list.items():\n",
    "    pass\n",
    "\n",
    "work_df.select([count(when(isnan('entdepd') | col('entdepd').isNull(), True))]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Exporting the data to Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#write to parquet\n",
    "df_spark.write.parquet(\"sas_data\")\n",
    "df_spark=spark.read.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Performing cleaning tasks here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Step 1 Section I - Scoping and Data Gathering\n",
    "**Task: Scope the Project and Gather Data**\n",
    "\n",
    "*Identify and gather the data you'll be using for your project (at least two sources and more than 1 million rows). See Project Resources for ideas of what data you can use.*\n",
    "\n",
    "*Explain what end use cases you'd like to prepare the data for (e.g., analytics table, app back-end, source-of-truth database, etc.)*\n",
    "\n",
    "\n",
    "## Step 1a - General Scope and Data Gathering Description\n",
    "The Udacity provided datasets for the Capstone Project include:\n",
    "* I94 Immigration data from 2016 provided by U.S. Customs and Border Protection agency\n",
    "* World Temperature Data\n",
    "* U.S. cities demographic data\n",
    "* An airport code table\n",
    "\n",
    "Each dataset has been collected at least once for assessment. The findings are included in the following chapters of this notebook, even if the dataset is not used in Step 2.\n",
    "\n",
    "Regarding the scope itself the following findings are relevant:\n",
    "* **I94 Immigration data** is considered **in scope** regarding the following analytical tasks:\n",
    "    * Develop a scalable automated extraction procedure using Spark Data Lake\n",
    "    * Load and Transform the data into fact and dimension tables\n",
    "    * Develop Airflow routines to manage the process\n",
    "* **Airport Codes** are considered **in scope** and will be used\n",
    "    * to enrich the immigration dataset with complete and updated values\n",
    "* **World Temperature data** is considered **out of scope** since no analytics questions for this dataset in conjunction with immigration data could be identified _and_ the datasets' time periods do not overlap\n",
    "* **Demographic data** is considered\n",
    "\n",
    "**Approach to describe and gather data**\n",
    "\n",
    "Descriptions for each dataset will be given in the sections below. Each description shall include:\n",
    "1. A first read of the dataset using Python and Pandas default methods\n",
    "1. \"First Impression\" notes about the extracted data\n",
    "1. Analysis of dataset documentation, enclosed data dictionaries, etc.\n",
    "1. Findings about Data Meaning, Quality, possible relationsships and definitions for\n",
    "    1. Numeric columns (including missing values, uniqueness and descriptive statistics)\n",
    "    1. Non-numeric columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 1 Section II - I94 Dataset of U.S. Customs and Border Protection department"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### A - I94 Immigration Dataset Description\n",
    "The dataset provided contains immigration data provided by US immigration authorities. Data is collected via form **I94** and contains data about people travelling from and to the US on people who are either **non United States citizens** or **lawful permanent residents** in the US.\n",
    "\n",
    "    “Form I-94, the Arrival-Departure Record Card, is a form used by the U.S. Customs and Border Protection (CBP) intended to keep track of the arrival and departure to/from the United States of people who are not United States citizens or lawful permanent residents (with the exception of those who are entering using the Visa Waiver Program or Compact of Free Association, using Border Crossing Cards, re-entering via automatic visa revalidation, or entering temporarily as crew members)” (https://en.wikipedia.org/wiki/Form_I-94)\n",
    "\n",
    "An overview of this dataset is also outlined [here] (https://travel.trade.gov/research/programs/i94/description.asp)\n",
    "\n",
    "Data files and formats:\n",
    "- Data files are stored in SAS (proprietary?) sas7bdat format\n",
    "- Per year a folder exists\n",
    "- Per month a file exists (~500 GB)\n",
    "\n",
    "Description file:\n",
    "- A description file for the fields was included, named *I94_SAS_Labels_Descriptions.SAS*\n",
    "- The file contains field descriptions for each column\n",
    "- And it contains value constraints for some columns, namely: *i94cnty, i94port, i94mode, i94addr*\n",
    "\n",
    "### B - I94 Immigration Data Data Gathering and first read\n",
    "\n",
    "As Pandas has a method to import SAS data we will be using this mechanism. The following code will read a defined number of lines only due to performance reasons.\n",
    "\n",
    "Reading the whole SAS file in the workspace resulted in long wait times for no obvious reason. Downloading and reading the file locally (4-Cores, 8GB laptop) took only 2-3 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'START reading SAS file ../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat, total filesize is: 450 Mb'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Importing lines from 1 to 50000 of total 100000 lines'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Importing lines from 50001 to 100000 of total 100000 lines'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'STOP reading SAS files'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'First lines of data and data types:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20130811</td>\n",
       "      <td>SEO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.736796e+09</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OS</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  depdate  i94bir  i94visa  count  dtadfile visapost occup entdepa entdepd entdepu matflag  biryear   dtaddto gender insnum airline        admnum  fltno visatype\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN     NaN      NaN    37.0      2.0    1.0       NaN      NaN   NaN       T     NaN       U     NaN   1979.0  10282016    NaN    NaN     NaN  1.897628e+09    NaN       B2\n",
       "1    7.0  2016.0     4.0   254.0   276.0     ATL  20551.0      1.0      AL      NaN    25.0      3.0    1.0  20130811      SEO   NaN       G     NaN       Y     NaN   1991.0       D/S      M    NaN     NaN  3.736796e+09  00296       F1\n",
       "2   15.0  2016.0     4.0   101.0   101.0     WAS  20545.0      1.0      MI  20691.0    55.0      2.0    1.0  20160401      NaN   NaN       T       O     NaN       M   1961.0  09302016      M    NaN      OS  6.666432e+08     93       B2\n",
       "3   16.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA  20567.0    28.0      2.0    1.0  20160401      NaN   NaN       O       O     NaN       M   1988.0  09302016    NaN    NaN      AA  9.246846e+10  00199       B2\n",
       "4   17.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA  20567.0     4.0      2.0    1.0  20160401      NaN   NaN       O       O     NaN       M   2012.0  09302016    NaN    NaN      AA  9.246846e+10  00199       B2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>object</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>object</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>float64</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>float64</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cicid    i94yr   i94mon   i94cit   i94res i94port  arrdate  i94mode i94addr  depdate   i94bir  i94visa    count dtadfile visapost   occup entdepa entdepd entdepu matflag  biryear dtaddto  gender  insnum airline   admnum   fltno visatype\n",
       "0  float64  float64  float64  float64  float64  object  float64  float64  object  float64  float64  float64  float64   object   object  object  object  object  object  object  float64  object  object  object  object  float64  object   object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'DONE reading SAS data in chunks, time elapsed is    3.73 seconds'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read in the data using a wrapper for the read_sas() method\n",
    "# Configuration\n",
    "sas_file =  '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "sas_file_format = 'sas7bdat'\n",
    "max_lines=100000     # Set the desired line number here\n",
    "for_lines=50000     # Set the desired lines for each cycle here\n",
    "\n",
    "sas_df = read_sas_in_chunks(sas_file, sas_file_format, max_lines, for_lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Summary on first read of data:**\n",
    "\n",
    "| **Column Name** | **Notes, comments and findings:**                  | **Recommended action items** |\n",
    "|------------|--------------------------------------------------|----------------------------|\n",
    "| all | (N) We are not importing everything here, since the files amount to about 6GB in total | |\n",
    "| |  (N) Using \"chunksize\" parameter and then breaking from the loop, so that we have handy 2.000 lines ||\n",
    "| all | In total 28 columns exist, 15 columns contain strings (object type) and 13 contain numbers (float64 type) | |\n",
    "| all | At first sight one can already spot unfamiliar date columns (arrdate, depdate, etc.) with various datatypes | |\n",
    "| all | Several rows have missing values | |\n",
    "| all | Some columns contain obviously integer values but float64 was assigned | |\n",
    "| all | Some categorical columns seem to exist | |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### C - Documentation and data description analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Documentation sources**\n",
    "\n",
    "A link was provided to the data source at the Visitor Arrivals Program: [LINK](https://travel.trade.gov/research/reports/i94/historical/2016.html)\n",
    "\n",
    "Following related pages were also analyzed:\n",
    "* Approved listing of [countries by world region](https://travel.trade.gov/research/programs/i94/1999-2020%20Region%20Dictionary.xlsx), stored as Excel file\n",
    "** Recommendation: use as source to validate data\n",
    "* A [Q&A section](https://travel.trade.gov/research/programs/ifs/qamythbuster.asp) which contains indications for completeness and accuracy of data\n",
    "** Those should be considered before making assumptions or draw conclusions from the data\n",
    "* Detailed descriptions about data collection [methodology](https://travel.trade.gov/research/programs/ifs/description.asp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Parsing the description file / data dictionary**\n",
    "\n",
    "The workspace contains a field description file for the dataset named `I94_SAS_Labels_Descriptions.SAS`\n",
    "\n",
    "The file seems pretty well structured, so I wrote a quick parser to automatically check the description file (see [SAS-Description-Parser](https://r766466c839826xjupyterlnnfq3jud.udacity-student-workspaces.com/lab/tree/SAS-Description-Parser.ipynb) for further details).\n",
    "\n",
    "**Definitions**\n",
    "\n",
    "| **Variable name** | **Data Type** | **Description** |\n",
    "|---------------|---------------|---------------|\n",
    "| i94yr | float64 | 4 digit year |\n",
    "| i94mon | float64 | Numeric month |\n",
    "| i94cit | float64 | This format shows all the valid and invalid codes for processing |\n",
    "| i94res | float64 | This format shows all the valid and invalid codes for processing |\n",
    "| i94port | object | This format shows all the valid and invalid codes for processing |\n",
    "| arrdate | float64 | is the Arrival Date in the USA. It is a SAS date numeric field that apermament format has not been applied.  Please apply whichever date formatpermament format has not been applied.  Please apply whichever date format |\n",
    "| i94mode | float64 | There are missing values as well as not reported (9) |\n",
    "| i94addr | object | There is lots of invalid codes in this variable and the list belowThere is lots of invalid codes in this variable and the list below |\n",
    "| depdate | float64 | is the Departure Date from the USA. It is a SAS date numeric field thata permament format has not been applied.  Please apply whichever date formata permament format has not been applied.  Please apply whichever date format |\n",
    "| i94bir | float64 | Age of Respondent in Years |\n",
    "| i94visa | float64 | Visa codes collapsed into three categories:1 = Business2 = Pleasure3 = Student*/ |\n",
    "| count | float64 | Used for summary statistics |\n",
    "| dtadfile | object | Character Date Field |\n",
    "| visapost | object | Department of State where where Visa was issued |\n",
    "| occup | object | Occupation that will be performed in U.S. |\n",
    "| entdepa | object | Arrival Flag |\n",
    "| entdepd | object | Departure Flag |\n",
    "| entdepu | object | Update Flag |\n",
    "| matflag | object | Match flag |\n",
    "| biryear | float64 | 4 digit year of birth |\n",
    "| dtaddto | object | Character Date Field |\n",
    "| gender | object | Non |\n",
    "| insnum | object | INS number |\n",
    "| airline | object | Airline used to arrive in U.S. |\n",
    "| admnum | float64 | Admission Number |\n",
    "| fltno | object | Flight number of Airline used to arrive in U.S. |\n",
    "| visatype | object | Class of admission legally admitting the non |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Summary on data documentation and descriptions:**\n",
    "\n",
    "| **Column Name** | **Notes, comments and findings:**                  | **Recommended action items** |\n",
    "|------------|--------------------------------------------------|----------------------------|\n",
    "| `i94cnty, i94port, i94mode, i94addr` | have value constraints (lists with allowed entry values) | Change data types, validate content (see below) | |\n",
    "| `i94cnty` | contains country short codes and their corresponding state names | Change to category field |\n",
    "| `i94port` | contains port/airport codes from various cities, without specific selection criteria as it seems (most of the codes are cities in the US but we also see city codes from Europe and Asia) | Change data type to string, Validate airport table using airport-codes_csv.csv| \n",
    "| `i94mode` | is a code for the way of travelling (by Air, by Sea or by Land) or unknown | Change to category field |\n",
    "| `i94addr` | is a code for the state in which this immigrants temporary address is located (aka \"First Intended Address\") | Change to category field |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### D - Analysis of numeric columns\n",
    "The Pandas describe() function creates a basic set of descriptive statistics for each numeric column in the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Running Data Quantifier with parameter: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' and example threshhold is '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'The dataframe has 100000 rows and 13 columns. Godspeed!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Quantifying NUMERIC data types in columns:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'cicid, i94yr, i94mon, i94cit, i94res, arrdate, i94mode, depdate, i94bir, i94visa, count, biryear, admnum'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>biryear</th>\n",
       "      <th>admnum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>100000.00000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>96194.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>1.000000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>78261.799790</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>296.76358</td>\n",
       "      <td>300.379380</td>\n",
       "      <td>20545.000340</td>\n",
       "      <td>1.005550</td>\n",
       "      <td>20560.189638</td>\n",
       "      <td>40.337100</td>\n",
       "      <td>1.907220</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1975.662900</td>\n",
       "      <td>7.012077e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>65475.726951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>208.55203</td>\n",
       "      <td>209.822608</td>\n",
       "      <td>0.090554</td>\n",
       "      <td>0.084849</td>\n",
       "      <td>22.703390</td>\n",
       "      <td>17.845464</td>\n",
       "      <td>0.341896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.845464</td>\n",
       "      <td>2.094554e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.00000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>20545.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20544.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1916.000000</td>\n",
       "      <td>3.984588e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>30037.750000</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.00000</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>20545.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20550.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1962.000000</td>\n",
       "      <td>5.543025e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>58714.500000</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.00000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>20545.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20553.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1976.000000</td>\n",
       "      <td>5.545761e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>91764.250000</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>464.00000</td>\n",
       "      <td>509.000000</td>\n",
       "      <td>20545.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20560.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1988.000000</td>\n",
       "      <td>9.246744e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>218060.000000</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>734.00000</td>\n",
       "      <td>749.000000</td>\n",
       "      <td>20573.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>20716.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>9.251712e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unique</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>180.00000</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Missing</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3806.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 cicid     i94yr    i94mon        i94cit         i94res        arrdate       i94mode       depdate         i94bir        i94visa     count        biryear        admnum\n",
       "count    100000.000000  100000.0  100000.0  100000.00000  100000.000000  100000.000000  99999.000000  96194.000000  100000.000000  100000.000000  100000.0  100000.000000  1.000000e+05\n",
       "mean      78261.799790    2016.0       4.0     296.76358     300.379380   20545.000340      1.005550  20560.189638      40.337100       1.907220       1.0    1975.662900  7.012077e+10\n",
       "std       65475.726951       0.0       0.0     208.55203     209.822608       0.090554      0.084849     22.703390      17.845464       0.341896       0.0      17.845464  2.094554e+10\n",
       "min           6.000000    2016.0       4.0     101.00000     101.000000   20545.000000      1.000000  20544.000000       0.000000       1.000000       1.0    1916.000000  3.984588e+07\n",
       "25%       30037.750000    2016.0       4.0     135.00000     131.000000   20545.000000      1.000000  20550.000000      28.000000       2.000000       1.0    1962.000000  5.543025e+10\n",
       "50%       58714.500000    2016.0       4.0     209.00000     209.000000   20545.000000      1.000000  20553.000000      40.000000       2.000000       1.0    1976.000000  5.545761e+10\n",
       "75%       91764.250000    2016.0       4.0     464.00000     509.000000   20545.000000      1.000000  20560.000000      54.000000       2.000000       1.0    1988.000000  9.246744e+10\n",
       "max      218060.000000    2016.0       4.0     734.00000     749.000000   20573.000000      9.000000  20716.000000     100.000000       3.000000       1.0    2016.000000  9.251712e+10\n",
       "Unique   100000.000000       1.0       1.0     180.00000     193.000000       3.000000      3.000000    172.000000     100.000000       3.000000       1.0     100.000000  1.000000e+05\n",
       "Missing       0.000000       0.0       0.0       0.00000       0.000000       0.000000      1.000000   3806.000000       0.000000       0.000000       0.0       0.000000  0.000000e+00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Columns with missing values:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'i94mode, depdate'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Columns with less than 10 unique values:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'i94yr, i94mon, arrdate, i94mode, i94visa, count'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Unique values in column 'i94yr': \""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'      2016'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Unique values in column 'i94mon': \""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'         4'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Unique values in column 'arrdate': \""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'     20573,      20551,      20545'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Unique values in column 'i94mode': \""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'         1,          2,          9'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Unique values in column 'i94visa': \""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'         2,          3,          1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Unique values in column 'count': \""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'         1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Data Quantification Done, time elapsed is    0.37 sec'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summarize_data(sas_df, ['numbers'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Summary on numeric data:**\n",
    "\n",
    "| **Column Name** | **Notes, comments and findings:**                  | **Recommended action items** |\n",
    "|------------|--------------------------------------------------|----------------------------|\n",
    "| `cicid` |is unique for all 2.000 lines (check `len(sas_df['cicid'].unique())`) and appears to be the primary key for each record | Change to int, Use as primary key|\n",
    "| | The following columns appear to indicate datetime related values: |\n",
    "| `i94yr` |indicating the year the I94 form was filled and 'i94mon' indicating the month | Change to int |\n",
    "| `arrdate` |is the immigrants arrival date | Change to datetime64 |\n",
    "| `depdate` |the date of the immigrants (planned) departure | Change to datetime64 |\n",
    "| `i94mode` | has already been identified as a category variable, the integers here are just codes indicating if the immigrant travelled by Land, Air or Sea (or unknown) | Change to category|\n",
    "| `i94visa` | was not identified correctly by my parser it seems, it has value constraints (* 1 = Business, 2 = Pleasure,3 = Student)  | Change to category|\n",
    "| `i94cit` and `i94res` | are again not numeric but indicate the immigrant's countries of citizenship (\"cit\") and residence (res) | Change to category, Validate date using value constraints |\n",
    "|`admnum` | is the admission number | Use as key variable to connect several rows |\n",
    "|`i94bir` |appears to be the immigrant's age at the time of admission (in other words it's the time delta between `i94yr`and `biryear` | Change to int|\n",
    "| `biryear` | marks the immigrants birthyear | Change to int |\n",
    "| `count` |is for statistical purposes according to the description | Change to int |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### E - Analysis of non-numeric columns\n",
    "Measuring the number of NaN entries and unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Running Data Quantifier with parameter: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' and example threshhold is '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'The dataframe has 100000 rows and 15 columns. Godspeed!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Quantifying NON-NUMERIC data types in columns:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'i94port, i94addr, dtadfile, visapost, occup, entdepa, entdepd, entdepu, matflag, dtaddto, gender, insnum, airline, fltno, visatype'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i94port</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Datatype</th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lines</th>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Non-Null</th>\n",
       "      <td>100000</td>\n",
       "      <td>96415</td>\n",
       "      <td>99999</td>\n",
       "      <td>39610</td>\n",
       "      <td>334</td>\n",
       "      <td>100000</td>\n",
       "      <td>96194</td>\n",
       "      <td>13</td>\n",
       "      <td>96194</td>\n",
       "      <td>99998</td>\n",
       "      <td>86465</td>\n",
       "      <td>0</td>\n",
       "      <td>99998</td>\n",
       "      <td>99999</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>3585</td>\n",
       "      <td>1</td>\n",
       "      <td>60390</td>\n",
       "      <td>99666</td>\n",
       "      <td>0</td>\n",
       "      <td>3806</td>\n",
       "      <td>99987</td>\n",
       "      <td>3806</td>\n",
       "      <td>2</td>\n",
       "      <td>13535</td>\n",
       "      <td>100000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fill-%</th>\n",
       "      <td>100</td>\n",
       "      <td>96.415</td>\n",
       "      <td>99.999</td>\n",
       "      <td>39.61</td>\n",
       "      <td>0.334</td>\n",
       "      <td>100</td>\n",
       "      <td>96.194</td>\n",
       "      <td>0.013</td>\n",
       "      <td>96.194</td>\n",
       "      <td>99.998</td>\n",
       "      <td>86.465</td>\n",
       "      <td>0</td>\n",
       "      <td>99.998</td>\n",
       "      <td>99.999</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unique</th>\n",
       "      <td>92</td>\n",
       "      <td>126</td>\n",
       "      <td>2</td>\n",
       "      <td>277</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>247</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "      <td>2206</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uniq-%</th>\n",
       "      <td>0.092</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0</td>\n",
       "      <td>0.173</td>\n",
       "      <td>2.206</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         i94port i94addr dtadfile visapost   occup entdepa entdepd entdepu matflag dtaddto  gender  insnum airline   fltno visatype\n",
       "Datatype  object  object   object   object  object  object  object  object  object  object  object  object  object  object   object\n",
       "Lines     100000  100000   100000   100000  100000  100000  100000  100000  100000  100000  100000  100000  100000  100000   100000\n",
       "Non-Null  100000   96415    99999    39610     334  100000   96194      13   96194   99998   86465       0   99998   99999   100000\n",
       "NaN            0    3585        1    60390   99666       0    3806   99987    3806       2   13535  100000       2       1        0\n",
       "Fill-%       100  96.415   99.999    39.61   0.334     100  96.194   0.013  96.194  99.998  86.465       0  99.998  99.999      100\n",
       "Unique        92     126        2      277      42       8       8       2       1     247       2       0     173    2206       14\n",
       "Uniq-%     0.092   0.126    0.002    0.277   0.042   0.008   0.008   0.002   0.001   0.247   0.002       0   0.173   2.206    0.014"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Columns with missing values:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'i94addr, dtadfile, visapost, occup, entdepd, entdepu, matflag, dtaddto, gender, insnum, airline, fltno'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Columns with less than 10 unique values:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'dtadfile, entdepa, entdepd, entdepu, matflag, gender, insnum'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Unique values in column 'dtadfile': \""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'20130811, 20160401'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Unique values in column 'entdepa': \""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'T, G, O, H, U, B, K, M'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Unique values in column 'entdepd': \""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'O, K, I, Q, R, N, M, J'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Unique values in column 'entdepu': \""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'U, Y'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Unique values in column 'matflag': \""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'M'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Unique values in column 'gender': \""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'M, F'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Unique values in column 'insnum': \""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Data Quantification Done, time elapsed is     1.6 sec'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summarize_data(sas_df, ['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Summary on non-numeric data:**\n",
    "\n",
    "| **Column Name** | **Notes, comments and findings:**                  | **Recommended action items** |\n",
    "|------------|--------------------------------------------------|----------------------------|\n",
    "| `i94prt, i94addr, dtadfile` | Value constraints exist | Change to category, Validate against list of constraints |\n",
    "| `dtadfile` |is the date on which the form was entered into the database | Change to datetime64 |\n",
    "| `dtaddto` |is the date the immigrant is admissioned to stay in the US | Change to datetime64 |\n",
    "| `visapost, occup` | rarely filled, not fit for analysis | \n",
    "| `entdepa, entdepd,entdepu,matflag,` | Unclear description in the data dictionary | Exclude from analyis |\n",
    "| `gender` | Immigrant gender | Change to category |\n",
    "| `insnum` | Immigration registration number, not filled in data sample | Check if field is filled in complete dataset | |\n",
    "| `visatype` | Type of issued visa | Check [online sources](https://travel.trade.gov/research/programs/i94/methodology.asp) for list of possible types |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### F - Dataset conclusion (Immigration Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Summary on non-numeric data:**\n",
    "\n",
    "| **Column Name** | **Commends and findings:**                  | **Recommended action items** |\n",
    "|------------|--------------------------------------------------|----------------------------|\n",
    "| <FELD> | <COMMENT, NOTE, FINDING> | <ACTION>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 1 Section III - World Temperature Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### A - World Temperature Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The World Temperature Dataset contains temperatures on land by city on a global scale. A detailed discription can be found [here](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data).\n",
    "\n",
    "The source indicates that other datasets exist which summarize the data e.g. by country or major cities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### B - Documentation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The dataset from kaggle provides a documentation on its hosting [site](https://www.kaggle.com/colinpbowen/starter-climate-change-earth-surface-e24bc90c-4)\n",
    "\n",
    "The set consists of seven columns:\n",
    "* `dt` is the temperatures measurement timestamp\n",
    "* `AverageTemperature` displays the average temperature in celsius degrees\n",
    "* `AgerageTemperatureUncertainty` shows possible deviations from average (95% confidence)\n",
    "* `City` - name of the city, has 3.448 distinct values\n",
    "* `Latitude, Longitude` - location of measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### C - World Temperature Data Gathering and first read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "As Pandas has a method to import CSV data we will be using this mechanism.\n",
    "\n",
    "Instead of reading just a chunk of the file we will read it in full here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'START reading CSV file ../../data2/GlobalLandTemperaturesByCity.csv of (Filesize: 5.1e+02 Mb)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty   City  Country Latitude Longitude\n",
       "0  1743-11-01               6.068                          1.737  Århus  Denmark   57.05N    10.33E\n",
       "1  1743-12-01                 NaN                            NaN  Århus  Denmark   57.05N    10.33E\n",
       "2  1744-01-01                 NaN                            NaN  Århus  Denmark   57.05N    10.33E\n",
       "3  1744-02-01                 NaN                            NaN  Århus  Denmark   57.05N    10.33E\n",
       "4  1744-03-01                 NaN                            NaN  Århus  Denmark   57.05N    10.33E"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Done. Operation took     9.9 seconds'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fname = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "temperature_df = read_csv_print(fname, ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Summary on first read:**\n",
    "\n",
    "| **Column Name** | **Commends and findings:**                  | **Recommended action items** |\n",
    "|------------|--------------------------------------------------|----------------------------|\n",
    "| all | Dataset contains in total over 8.5m rows | |\n",
    "| `dt` | starting in 1743 | Convert to datetime64 |\n",
    "| `AverageTemperature` | mind the missing values | Check for isna() |\n",
    "| `AverageTemperatureUncertainty` | same as above | |\n",
    "| `City, Country` | None | |\n",
    "| `Latitude, Longitude` | |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### D - Analysis of numeric columns in Temperature Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Only two numeric columns were identified:  `AverageTemperature`, `AverageTemperatureUncertainty`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Running Data Quantifier with parameter: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' and example threshhold is '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'The dataframe has 8599212 rows and 2 columns. Godspeed!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Quantifying NUMERIC data types in columns:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'AverageTemperature, AverageTemperatureUncertainty'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.235082e+06</td>\n",
       "      <td>8.235082e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.672743e+01</td>\n",
       "      <td>1.028575e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.035344e+01</td>\n",
       "      <td>1.129733e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.270400e+01</td>\n",
       "      <td>3.400000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.029900e+01</td>\n",
       "      <td>3.370000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.883100e+01</td>\n",
       "      <td>5.910000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.521000e+01</td>\n",
       "      <td>1.349000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.965100e+01</td>\n",
       "      <td>1.539600e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unique</th>\n",
       "      <td>1.119940e+05</td>\n",
       "      <td>1.090200e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Missing</th>\n",
       "      <td>3.641300e+05</td>\n",
       "      <td>3.641300e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         AverageTemperature  AverageTemperatureUncertainty\n",
       "count          8.235082e+06                   8.235082e+06\n",
       "mean           1.672743e+01                   1.028575e+00\n",
       "std            1.035344e+01                   1.129733e+00\n",
       "min           -4.270400e+01                   3.400000e-02\n",
       "25%            1.029900e+01                   3.370000e-01\n",
       "50%            1.883100e+01                   5.910000e-01\n",
       "75%            2.521000e+01                   1.349000e+00\n",
       "max            3.965100e+01                   1.539600e+01\n",
       "Unique         1.119940e+05                   1.090200e+04\n",
       "Missing        3.641300e+05                   3.641300e+05"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Columns with missing values:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'AverageTemperature, AverageTemperatureUncertainty'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Columns with less than 10 unique values:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Data Quantification Done, time elapsed is     3.4 sec'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summarize_data(temperature_df, ['numbers'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Summary on numeric data:**\n",
    "\n",
    "| **Column Name** | **Notes, comments and findings:**                  | **Recommended action items** |\n",
    "|------------|--------------------------------------------------|----------------------------|\n",
    "| `AverageTemperature` | About 364.000 missing values | Exclude NaN from analysis |\n",
    "| | \n",
    "| `AverageTemperatureUncertainty` | About 364.000 missing values, which is expected due to missing temperature data | Exclude NaN from analysis |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### E - Analysis of non-numeric columns in Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Non-numeric data columns, qualitative analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Running Data Quantifier with parameter: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' and example threshhold is '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'The dataframe has 8599212 rows and 5 columns. Godspeed!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Quantifying NON-NUMERIC data types in columns:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'dt, City, Country, Latitude, Longitude'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Datatype</th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lines</th>\n",
       "      <td>8599212</td>\n",
       "      <td>8599212</td>\n",
       "      <td>8599212</td>\n",
       "      <td>8599212</td>\n",
       "      <td>8599212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Non-Null</th>\n",
       "      <td>8599212</td>\n",
       "      <td>8599212</td>\n",
       "      <td>8599212</td>\n",
       "      <td>8599212</td>\n",
       "      <td>8599212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fill-%</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unique</th>\n",
       "      <td>3239</td>\n",
       "      <td>3448</td>\n",
       "      <td>159</td>\n",
       "      <td>73</td>\n",
       "      <td>1227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uniq-%</th>\n",
       "      <td>0.0376662</td>\n",
       "      <td>0.0400967</td>\n",
       "      <td>0.00184901</td>\n",
       "      <td>0.000848915</td>\n",
       "      <td>0.0142687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 dt       City     Country     Latitude  Longitude\n",
       "Datatype     object     object      object       object     object\n",
       "Lines       8599212    8599212     8599212      8599212    8599212\n",
       "Non-Null    8599212    8599212     8599212      8599212    8599212\n",
       "NaN               0          0           0            0          0\n",
       "Fill-%          100        100         100          100        100\n",
       "Unique         3239       3448         159           73       1227\n",
       "Uniq-%    0.0376662  0.0400967  0.00184901  0.000848915  0.0142687"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Columns with missing values:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Columns with less than 10 unique values:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Data Quantification Done, time elapsed is   2e+01 sec'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summarize_data(temperature_df, ['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The last datapoint is from the following date: 2013-09-01\n"
     ]
    }
   ],
   "source": [
    "# Convert \"dt\" to datetime and sort, then check latest measurement date\n",
    "\n",
    "temperature_df[['dt']] = temperature_df[['dt']].astype('datetime64')\n",
    "temperature_df = temperature_df.sort_values(by=['dt'], ascending=False)\n",
    "print('The last datapoint is from the following date: {:.10}'.format(temperature_df['dt'].head(1).values[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average datapoints per city:   2494 entries\n",
      "City with most data points: Springfield\t\t\t9545 entries\n",
      "City with least data points: Port Moresby\t\t\t1581 entries\n"
     ]
    }
   ],
   "source": [
    "# Check distribution of data points per City\n",
    "\n",
    "# Count datapoints per city\n",
    "count_df = temperature_df[['City', 'dt']].copy()\n",
    "count_df = count_df.groupby(by=['City']).count()\n",
    "count_df = count_df.sort_values(by='dt', ascending=False)\n",
    "entries = len(temperature_df)\n",
    "num_of_cit = len(count_df)\n",
    "print('Average datapoints per city: {:6.0f} entries'.format((entries / num_of_cit)))\n",
    "print('City with most data points: {}\\t\\t\\t{} entries'.format(count_df.head(1).index[0], count_df['dt'].head(1).values[0]))\n",
    "print('City with least data points: {}\\t\\t\\t{} entries'.format(count_df.tail(1).index[0], count_df['dt'].tail(1).values[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Summary:**\n",
    "\n",
    "| **Column Name** | **Notes, comments and findings:**                  | **Recommended action items** |\n",
    "|------------|--------------------------------------------------|----------------------------|\n",
    "| `City, dt` | city names and timestamps are one possible way to **link this dataset to the I94 immigration data** | Join datasets on a combined key of both fields\n",
    "| `dt` | The \"freshest\" data point is from September 2013 |  |\n",
    "| all | There is a significant **imbalance in the number of data points**: While the average is 2.494 entries, the city with most entries has 9.545 and the city with least entries has 1.581 entries | |\n",
    "| all | Also the datapoints per day are varying between about 700 and 3500 per day | |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### F - Dataset conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The \"World Temperature Dataset\" could be linked to the I94 immigration data by a combined key of `City`and `dt`. This would allow to add temperature data as dimension table when analyzing immigration data.\n",
    "\n",
    "However the dataset is not well suited to be analyzed in conjunction with the Immigration Data, since there is **no time period overlap**. Without temperature data from the time period of the provided immigration data no signifant findings from data analyses can be expected.\n",
    "\n",
    "**Conclusion**: the World Temperature Dataset is ruled **out of scope**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 1 Section IV - U.S. City Demographic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### A - Demographic Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "A dataset of demographic data is provided from [opendatasoft](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/). It contains statistic about the population structure in various U.S. cities with a population greater or equal to 65,000.\n",
    "\n",
    "The data was gathered in the US Census Bureau's 2015 American Community Survey."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### B - Demographic Data Gathering and first read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We will use Pandas standard CSV reading method and read the complete file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'START reading CSV file us-cities-demographics.csv of (Filesize:    0.24 Mb)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  Female Population  Total Population  Number of Veterans  Foreign-born  Average Household Size State Code                       Race  Count\n",
       "0     Silver Spring       Maryland        33.8          40601.0            41862.0             82463              1562.0       30908.0                    2.60         MD         Hispanic or Latino  25924\n",
       "1            Quincy  Massachusetts        41.0          44129.0            49500.0             93629              4147.0       32935.0                    2.39         MA                      White  58723\n",
       "2            Hoover        Alabama        38.5          38040.0            46799.0             84839              4819.0        8229.0                    2.58         AL                      Asian   4759\n",
       "3  Rancho Cucamonga     California        34.5          88127.0            87105.0            175232              5821.0       33878.0                    3.18         CA  Black or African-American  24437\n",
       "4            Newark     New Jersey        34.6         138040.0           143873.0            281913              5829.0       86253.0                    2.73         NJ                      White  76402"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Done. Operation took   0.044 seconds'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fname = \"us-cities-demographics.csv\"\n",
    "dem_data_df = read_csv_print(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### C - Documentation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The dataset's documentation is rather brief and available  [online](https://public.opendatasoft.com/explore/embed/dataset/us-cities-demographics/table/?dataChart=eyJxdWVyaWVzIjpbeyJjb25maWciOnsiZGF0YXNldCI6InVzLWNpdGllcy1kZW1vZ3JhcGhpY3MiLCJvcHRpb25zIjp7fX0sImNoYXJ0cyI6W3siYWxpZ25Nb250aCI6dHJ1ZSwidHlwZSI6ImNvbHVtbiIsImZ1bmMiOiJBVkciLCJ5QXhpcyI6Im1lZGlhbl9hZ2UiLCJzY2llbnRpZmljRGlzcGxheSI6dHJ1ZSwiY29sb3IiOiIjRkY1MTVBIn1dLCJ4QXhpcyI6ImNpdHkiLCJtYXhwb2ludHMiOjUwLCJzb3J0IjoiIn1dLCJ0aW1lc2NhbGUiOiIiLCJkaXNwbGF5TGVnZW5kIjp0cnVlLCJhbGlnbk1vbnRoIjp0cnVlfQ%3D%3D). Meanings of column headings are pretty self-explanatory. No deeper analysis required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### D - Analysis of numeric columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The demographic data contains various numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Running Data Quantifier with parameter: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' and example threshhold is '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'The dataframe has 2891 rows and 8 columns. Godspeed!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Quantifying NUMERIC data types in columns:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Median Age, Male Population, Female Population, Total Population, Number of Veterans, Foreign-born, Average Household Size, Count'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2891.000000</td>\n",
       "      <td>2.888000e+03</td>\n",
       "      <td>2.888000e+03</td>\n",
       "      <td>2.891000e+03</td>\n",
       "      <td>2878.000000</td>\n",
       "      <td>2.878000e+03</td>\n",
       "      <td>2875.000000</td>\n",
       "      <td>2.891000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>35.494881</td>\n",
       "      <td>9.732843e+04</td>\n",
       "      <td>1.017696e+05</td>\n",
       "      <td>1.989668e+05</td>\n",
       "      <td>9367.832523</td>\n",
       "      <td>4.065360e+04</td>\n",
       "      <td>2.742543</td>\n",
       "      <td>4.896377e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.401617</td>\n",
       "      <td>2.162999e+05</td>\n",
       "      <td>2.315646e+05</td>\n",
       "      <td>4.475559e+05</td>\n",
       "      <td>13211.219924</td>\n",
       "      <td>1.557491e+05</td>\n",
       "      <td>0.433291</td>\n",
       "      <td>1.443856e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>22.900000</td>\n",
       "      <td>2.928100e+04</td>\n",
       "      <td>2.734800e+04</td>\n",
       "      <td>6.321500e+04</td>\n",
       "      <td>416.000000</td>\n",
       "      <td>8.610000e+02</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.800000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>32.800000</td>\n",
       "      <td>3.928900e+04</td>\n",
       "      <td>4.122700e+04</td>\n",
       "      <td>8.042900e+04</td>\n",
       "      <td>3739.000000</td>\n",
       "      <td>9.224000e+03</td>\n",
       "      <td>2.430000</td>\n",
       "      <td>3.435000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>35.300000</td>\n",
       "      <td>5.234100e+04</td>\n",
       "      <td>5.380900e+04</td>\n",
       "      <td>1.067820e+05</td>\n",
       "      <td>5397.000000</td>\n",
       "      <td>1.882200e+04</td>\n",
       "      <td>2.650000</td>\n",
       "      <td>1.378000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>8.664175e+04</td>\n",
       "      <td>8.960400e+04</td>\n",
       "      <td>1.752320e+05</td>\n",
       "      <td>9368.000000</td>\n",
       "      <td>3.397175e+04</td>\n",
       "      <td>2.950000</td>\n",
       "      <td>5.444700e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>70.500000</td>\n",
       "      <td>4.081698e+06</td>\n",
       "      <td>4.468707e+06</td>\n",
       "      <td>8.550405e+06</td>\n",
       "      <td>156961.000000</td>\n",
       "      <td>3.212500e+06</td>\n",
       "      <td>4.980000</td>\n",
       "      <td>3.835726e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unique</th>\n",
       "      <td>180.000000</td>\n",
       "      <td>5.930000e+02</td>\n",
       "      <td>5.940000e+02</td>\n",
       "      <td>5.940000e+02</td>\n",
       "      <td>577.000000</td>\n",
       "      <td>5.870000e+02</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>2.785000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Missing</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.300000e+01</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Median Age  Male Population  Female Population  Total Population  Number of Veterans  Foreign-born  Average Household Size         Count\n",
       "count    2891.000000     2.888000e+03       2.888000e+03      2.891000e+03         2878.000000  2.878000e+03             2875.000000  2.891000e+03\n",
       "mean       35.494881     9.732843e+04       1.017696e+05      1.989668e+05         9367.832523  4.065360e+04                2.742543  4.896377e+04\n",
       "std         4.401617     2.162999e+05       2.315646e+05      4.475559e+05        13211.219924  1.557491e+05                0.433291  1.443856e+05\n",
       "min        22.900000     2.928100e+04       2.734800e+04      6.321500e+04          416.000000  8.610000e+02                2.000000  9.800000e+01\n",
       "25%        32.800000     3.928900e+04       4.122700e+04      8.042900e+04         3739.000000  9.224000e+03                2.430000  3.435000e+03\n",
       "50%        35.300000     5.234100e+04       5.380900e+04      1.067820e+05         5397.000000  1.882200e+04                2.650000  1.378000e+04\n",
       "75%        38.000000     8.664175e+04       8.960400e+04      1.752320e+05         9368.000000  3.397175e+04                2.950000  5.444700e+04\n",
       "max        70.500000     4.081698e+06       4.468707e+06      8.550405e+06       156961.000000  3.212500e+06                4.980000  3.835726e+06\n",
       "Unique    180.000000     5.930000e+02       5.940000e+02      5.940000e+02          577.000000  5.870000e+02              161.000000  2.785000e+03\n",
       "Missing     0.000000     3.000000e+00       3.000000e+00      0.000000e+00           13.000000  1.300000e+01               16.000000  0.000000e+00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Columns with missing values:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Male Population, Female Population, Number of Veterans, Foreign-born, Average Household Size'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Columns with less than 10 unique values:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Data Quantification Done, time elapsed is    0.11 sec'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summarize_data(dem_data_df, ['numbers'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Summary:**\n",
    "\n",
    "* All columns contain integer values with the exception of `Median Age` and `Average Household Size` which are floating point values\n",
    "* Only a limited amounts of values are missing,the dataset seems rather complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### E - Analysis of non-numeric columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The demographic dataset contains some string data which will be analyzed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Running Data Quantifier with parameter: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' and example threshhold is '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'The dataframe has 2891 rows and 4 columns. Godspeed!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Quantifying NON-NUMERIC data types in columns:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'City, State, State Code, Race'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Datatype</th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lines</th>\n",
       "      <td>2891</td>\n",
       "      <td>2891</td>\n",
       "      <td>2891</td>\n",
       "      <td>2891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Non-Null</th>\n",
       "      <td>2891</td>\n",
       "      <td>2891</td>\n",
       "      <td>2891</td>\n",
       "      <td>2891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fill-%</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unique</th>\n",
       "      <td>567</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uniq-%</th>\n",
       "      <td>19.6126</td>\n",
       "      <td>1.69492</td>\n",
       "      <td>1.69492</td>\n",
       "      <td>0.172951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             City    State State Code      Race\n",
       "Datatype   object   object     object    object\n",
       "Lines        2891     2891       2891      2891\n",
       "Non-Null     2891     2891       2891      2891\n",
       "NaN             0        0          0         0\n",
       "Fill-%        100      100        100       100\n",
       "Unique        567       49         49         5\n",
       "Uniq-%    19.6126  1.69492    1.69492  0.172951"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Columns with missing values:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Columns with less than 10 unique values:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Race'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Unique values in column 'Race': \""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Hispanic or Latino, White, Asian, Black or African-American, American Indian and Alaska Native'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Data Quantification Done, time elapsed is   0.094 sec'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summarize_data(dem_data_df, ['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Summary:**\n",
    "\n",
    "| **Column Name** | **Notes, comments and findings:**                  | **Recommended action items** |\n",
    "|------------|--------------------------------------------------|----------------------------|\n",
    "| `City` | can be used to link data to I94 immigration dataset | Apply as key |\n",
    "| `State Code` | can be used to link data to I94 immigration dataset | Apply as key |\n",
    "| `Race` | Only 5 different values exist indicating this column as a category | Add category/ dimension |\n",
    "| `all` | No missing values | |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### F - Dataset conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Summary:**\n",
    "\n",
    "* The demographic dataset appears to be of good quality with few missing values\n",
    "* The dataset has only a limited files of 0.24 Mb\n",
    "* It can be linked to the immigration dataset, for instance to research relations between demographics and travelling patterns\n",
    "\n",
    "**Conclusion**: The dataset on U.S. city demographics is considered **in scope**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 1 Section V - Airport Code Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### A - Airport Code Table Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "A list of airports from [datahub.io](https://datahub.io/core/airport-codes#data) with various datapoints was provided for this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### B - Airport Code Table Data Gathering and first read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Again we will be using Pandas CSV Reader and import the complete file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'START reading CSV file airport-codes_csv.csv of (Filesize:     5.7 Mb)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name  elevation_ft continent iso_country iso_region  municipality gps_code iata_code local_code                            coordinates\n",
       "0   00A       heliport                   Total Rf Heliport          11.0       NaN          US      US-PA      Bensalem      00A       NaN        00A     -74.93360137939453, 40.07080078125\n",
       "1  00AA  small_airport                Aero B Ranch Airport        3435.0       NaN          US      US-KS         Leoti     00AA       NaN       00AA                 -101.473911, 38.704022\n",
       "2  00AK  small_airport                        Lowell Field         450.0       NaN          US      US-AK  Anchor Point     00AK       NaN       00AK            -151.695999146, 59.94919968\n",
       "3  00AL  small_airport                        Epps Airpark         820.0       NaN          US      US-AL       Harvest     00AL       NaN       00AL  -86.77030181884766, 34.86479949951172\n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport         237.0       NaN          US      US-AR       Newport      NaN       NaN        NaN                    -91.254898, 35.6087"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Done. Operation took    0.28 seconds'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fname = 'airport-codes_csv.csv'\n",
    "airport_df = read_csv_print(fname, ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### C - Documentation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "According to the documentation found online, the list contains the following data:\n",
    "* either IATA airport codes consisting of 3 letters\n",
    "* or ICAO codes consisting of 4 letters\n",
    "\n",
    "The list contains over 50.000 entries for airports and adds information for each airport such as:\n",
    "* additional codes like local codes\n",
    "* location information such as city, country and geo-coordinates\n",
    "* elevation of the airport above sea-level\n",
    "* type of airport (is it Newark or just a helipad?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### D - Analysis of numeric columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "`elevation_ft` is the only numeric field in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Running Data Quantifier with parameter: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' and example threshhold is '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'The dataframe has 55075 rows and 1 columns. Godspeed!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Quantifying NUMERIC data types in columns:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'elevation_ft'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elevation_ft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48069.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1240.789677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1602.363459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1266.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>205.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>718.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1497.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>22000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unique</th>\n",
       "      <td>5449.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Missing</th>\n",
       "      <td>7006.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         elevation_ft\n",
       "count    48069.000000\n",
       "mean      1240.789677\n",
       "std       1602.363459\n",
       "min      -1266.000000\n",
       "25%        205.000000\n",
       "50%        718.000000\n",
       "75%       1497.000000\n",
       "max      22000.000000\n",
       "Unique    5449.000000\n",
       "Missing   7006.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Columns with missing values:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'elevation_ft'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Columns with less than 10 unique values:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Data Quantification Done, time elapsed is   0.072 sec'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summarize_data(airport_df, 'numbers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### E - Analysis of non-numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Running Data Quantifier with parameter: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' and example threshhold is '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'The dataframe has 55075 rows and 11 columns. Godspeed!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Quantifying NON-NUMERIC data types in columns:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'ident, type, name, continent, iso_country, iso_region, municipality, gps_code, iata_code, local_code, coordinates'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Datatype</th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lines</th>\n",
       "      <td>55075</td>\n",
       "      <td>55075</td>\n",
       "      <td>55075</td>\n",
       "      <td>55075</td>\n",
       "      <td>55075</td>\n",
       "      <td>55075</td>\n",
       "      <td>55075</td>\n",
       "      <td>55075</td>\n",
       "      <td>55075</td>\n",
       "      <td>55075</td>\n",
       "      <td>55075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Non-Null</th>\n",
       "      <td>55075</td>\n",
       "      <td>55075</td>\n",
       "      <td>55075</td>\n",
       "      <td>27356</td>\n",
       "      <td>54828</td>\n",
       "      <td>55075</td>\n",
       "      <td>49399</td>\n",
       "      <td>41030</td>\n",
       "      <td>9189</td>\n",
       "      <td>28686</td>\n",
       "      <td>55075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27719</td>\n",
       "      <td>247</td>\n",
       "      <td>0</td>\n",
       "      <td>5676</td>\n",
       "      <td>14045</td>\n",
       "      <td>45886</td>\n",
       "      <td>26389</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fill-%</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>49.6704</td>\n",
       "      <td>99.5515</td>\n",
       "      <td>100</td>\n",
       "      <td>89.6941</td>\n",
       "      <td>74.4984</td>\n",
       "      <td>16.6845</td>\n",
       "      <td>52.0853</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unique</th>\n",
       "      <td>55075</td>\n",
       "      <td>7</td>\n",
       "      <td>52144</td>\n",
       "      <td>6</td>\n",
       "      <td>243</td>\n",
       "      <td>2810</td>\n",
       "      <td>27133</td>\n",
       "      <td>40850</td>\n",
       "      <td>9042</td>\n",
       "      <td>27436</td>\n",
       "      <td>54874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uniq-%</th>\n",
       "      <td>100</td>\n",
       "      <td>0.0127099</td>\n",
       "      <td>94.6782</td>\n",
       "      <td>0.0108942</td>\n",
       "      <td>0.441217</td>\n",
       "      <td>5.10213</td>\n",
       "      <td>49.2655</td>\n",
       "      <td>74.1716</td>\n",
       "      <td>16.4176</td>\n",
       "      <td>49.8157</td>\n",
       "      <td>99.635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ident       type     name  continent iso_country iso_region municipality gps_code iata_code local_code coordinates\n",
       "Datatype  object     object   object     object      object     object       object   object    object     object      object\n",
       "Lines      55075      55075    55075      55075       55075      55075        55075    55075     55075      55075       55075\n",
       "Non-Null   55075      55075    55075      27356       54828      55075        49399    41030      9189      28686       55075\n",
       "NaN            0          0        0      27719         247          0         5676    14045     45886      26389           0\n",
       "Fill-%       100        100      100    49.6704     99.5515        100      89.6941  74.4984   16.6845    52.0853         100\n",
       "Unique     55075          7    52144          6         243       2810        27133    40850      9042      27436       54874\n",
       "Uniq-%       100  0.0127099  94.6782  0.0108942    0.441217    5.10213      49.2655  74.1716   16.4176    49.8157      99.635"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Columns with missing values:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'continent, iso_country, municipality, gps_code, iata_code, local_code'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Columns with less than 10 unique values:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'type, continent'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Unique values in column 'type': \""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'heliport, small_airport, closed, seaplane_base, balloonport, medium_airport, large_airport'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Unique values in column 'continent': \""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'OC, AF, AN, EU, AS, SA'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Data Quantification Done, time elapsed is    0.39 sec'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summarize_data(airport_df, 'objects')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Summary on non-numeric columns:**\n",
    "\n",
    "| **Column Name** | **Notes, comments and findings:**                  | **Recommended action items** |\n",
    "|------------|--------------------------------------------------|----------------------------|\n",
    "| `continent, iso_country, municipality, gps_code, iata_code, local_code` | all fields would be suitable analytics dimensions, but the `*_code`columns show a high number of empty cells | Analyze possible hidden duplicates (e.g. by comparing location data) to improve data quality |\n",
    "| `type, continent` | while `type` columns is completely filled, `continent` has about 50% missing values | Use column `iso_country` to update continents |\n",
    "| `iata_code` | high amount of missing values but still should be tried to match to column `i94port` of the immigration dataset |\n",
    "| `iso_region, municipality` | Possibly matching to `i94addr` | Remove prefix \"US-\" and join tables |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### F - Dataset conclusion on airport codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Summary:**\n",
    "\n",
    "* The dataset offers various analytical dimensions e.g.\n",
    "    * the `type` column adds a bit of detail to airports immigrants use\n",
    "    * the `coordinates` column may be used to create geo-visulizations\n",
    "    * `name` and `iata_codes` can be used to enrich available data points\n",
    "* The dataset should be considered in scope since it is possible to link it with immigration data using one of two columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 1 Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "For analyzing the immigration dataset 3 possible datasets were suggested as possible analysis dimensions and data sources: world temperature data, U.S. cities demographic data and a detailed information about airports\n",
    "\n",
    "The world temperature dataset was moved out of the project scope since it does not contain temperature data from the available immigration dataset's time period.\n",
    "\n",
    "The airport codes and demographics data can be linked with the immigration data via location names or codes. Thus it is being considered in scope of this project.\n",
    "\n",
    "While both datasets are rather limited in size (5.7 and 0.24 Megabytes) the immigration dataset is comparably large. For production use a scalable import tool is required.\n",
    "\n",
    "For many columns quality characteristics were identified like suggesting possible categorical data types, fill methods for missing values and relationship key fields. Those recommendations will be implemented in Step 4 of this project.\n",
    "\n",
    "Step 1 of this project created a more technical understanding of the data and its quality. In Step 2 some explorative analysis will be performed to learn more about required data cleaning actions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Performing cleaning tasks here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Perform quality checks here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
